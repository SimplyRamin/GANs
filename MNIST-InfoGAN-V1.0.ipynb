{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info GAN - MNIST Dataset\n",
    "\n",
    "In this notebook we are going to implement a fairly complicated GAN, called InfoGAN. This architecture is based on the paper, [InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets](https://arxiv.org/abs/1606.03657) by Chen et al.\n",
    "\n",
    "The main problem this architecture is seeking to fix is the disentanglement issue, and using this approach is more widely used and known in community.\n",
    "\n",
    "The interpretation of how InfoGAN work in high-level language is like this; we separate the model into two parts: 1. First part corresponding to truly random noise, 2. Second part is corresponding to the something we call \"latent code\".\n",
    "\n",
    "The latent code can be thought as a \"hidden\" condition in a conditional generator, we actually want this to have an interpretable meaning.\n",
    "\n",
    "It's the most likely that you are wondering how do we get the latent code, a set of random number to be more interpretable than any dimension in a GAN? The answer to this question is \"Mutual Information\". We want each dimension of the latent code to be as obvious a function as possible of generated images. We won't go any deeper than this, if you want to read more about this matter, I suggest read the reference paper and Information Entropy.\n",
    "\n",
    "The implementation of InfoGAN is much like before, generator is just like previous models, but the discriminators will undergo some changes. To be more specific, it will be modified in a way so more dimensions are present in its output.\n",
    "\n",
    "Architecture of this network is:\n",
    "\n",
    "Generator:\n",
    "1. Noise Vector: (64 + 2)\n",
    "2. Block 1: [ConvTranspose(66, 256)] -> Batch Normalization (256) -> ReLU\n",
    "3. Block 2: [ConvTranspose(256, 128), Filter: 4, Stride: 1] -> Batch Normalization (128) -> ReLU\n",
    "4. Block 3: [ConvTranspose(128, 64)] -> Batch Normalization (64) -> ReLU\n",
    "5. Block 4: [ConvTranspose(64, 1)] -> TanH\n",
    "\n",
    "Discriminator:\n",
    "1. Image: (28, 28, 1)*\n",
    "2. Block 1: [Conv2D(1, 64)] -> Batch Normalization (64) -> LeakyReLU (0.2)\n",
    "3. Block 2: [Conv2D(64, 128)] -> Batch Normalization (128) -> LeakyReLU (0.2)\n",
    "4. D Layer: [Conv2D(128, 1)]\n",
    "5. Q Layer 1: [Conv2D(128, 128)] -> Batch Normalization (128) -> LeakyReLU (0.2)\n",
    "6. Q Layer 2: [Conv2D(128, 4), Filter: 1]\n",
    "\n",
    "\n",
    "*: In mathematics notation, the channel layer is presented as the third dimension but in tensor processing libraries it's presented as the first dimension of a cube. i.e. (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_tensor_images(image_tensor, num_images=25, size=(1, 28, 28), nrow=5, show=True):\n",
    "    '''\n",
    "    Function for visualizing images: Given a tensor of images, number of images, and\n",
    "    size per image, plots and prints the images in an uniform grid.\n",
    "    '''\n",
    "    image_tensor = (image_tensor + 1) / 2\n",
    "    image_unflat = image_tensor.detach().cpu()\n",
    "    image_grid = make_grid(image_unflat[:num_images], nrow=nrow)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0).squeeze())\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def generate_noise(n_samples, noise_dim, device = 'cpu'):\n",
    "    '''\n",
    "    A Helper function for creating random noise vectors with the dimension of: (n_samples, noise_dim)\n",
    "    random numbers are from normal distribution\n",
    "    Input ->\n",
    "        n_samples: number of samples to generate (row)\n",
    "        noise_dim: dimension of nouse vector (column)\n",
    "        device: device type\n",
    "    '''\n",
    "    return torch.randn(n_samples, noise_dim, device=device)\n",
    "\n",
    "def combine_vectors(x, y):\n",
    "    '''\n",
    "    Function for combining two vectors with shapes (n_samples, ?) and (n_samples, ?).\n",
    "    Input ->\n",
    "      x: (n_samples, ?) the first vector. \n",
    "        This will be the noise vector of shape (n_samples, z_dim).\n",
    "      y: (n_samples, ?) the second vector.\n",
    "        Once again, in this example this will be the one-hot class vector \n",
    "        with the shape (n_samples, n_classes).\n",
    "    '''\n",
    "    combined = torch.cat([x.float(), y.float()], 1)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    '''\n",
    "    This class is for generator.\n",
    "    Inputs ->\n",
    "        noise_dim: dimension of noise vector.\n",
    "        image_channel: number of channels in images,(Since MNIST is black and white images have 1 channel.)\n",
    "        hidden_dim: inner dimension of networks.\n",
    "    '''\n",
    "    def __init__(self, noise_dim=10, image_channel=1, hidden_dim=64):\n",
    "        super(Generator, self).__init__()\n",
    "        self.noise_dim = noise_dim\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, hidden_dim*4),\n",
    "            nn.BatchNorm2d(hidden_dim * 4),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim * 4, hidden_dim * 2, kernel_size=4, stride=1),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim * 2, hidden_dim),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.block4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(hidden_dim, image_channel, kernel_size=4),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        '''\n",
    "        forward pass of generator.\n",
    "        Input ->\n",
    "            noise: noise tensor with shape of (number of samples, noise_dim)\n",
    "        Output ->\n",
    "            generated image\n",
    "        '''\n",
    "        out = noise.view(len(noise), self.noise_dim, 1, 1)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "As you can see in the beginning of this notebook, the final layer of discriminator has 4 channels as output instead of one. The reason behind this fact is that we have to predict a distribution for $c$ from $x$. Since we are assuming a normal prior, we can output a mean and a log-variance prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    '''\n",
    "    This class is for Dsicriminator\n",
    "    Input ->\n",
    "        image_channel: number of channels in images,(Since MNIST is black and white images have 1 channel.)\n",
    "        hidden_dim: inner dimension of networks.\n",
    "        c_dim: number of latent code dimensions\n",
    "    '''\n",
    "    def __init__(self, image_channel=1, hidden_dim=64, c_dim=10):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(image_channel, hidden_dim),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, hidden_dim * 2),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        )\n",
    "        self.d_layer = nn.Conv2d(hidden_dim * 2, 1)\n",
    "        self.q_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim * 2, hidden_dim * 2),\n",
    "            nn.BatchNorm2d(hidden_dim * 2),\n",
    "            nn.LeakyReLU(.2, inplace=True)\n",
    "        )\n",
    "        self.q_layer2 = nn.Conv2d(hidden_dim * 2, c_dim * 2, kernel_size=1)\n",
    "    \n",
    "    def forward(self, image):\n",
    "        '''\n",
    "        Forward pass of discriminator\n",
    "        Input ->\n",
    "            image: flattened image tensor with dimension of (image_dim)\n",
    "        Output ->\n",
    "            returns a 1 dimension tensor representing whtether input image is generated or original.\n",
    "        '''\n",
    "        out = self.block1(image)\n",
    "        intermed_pred = self.block2(out)\n",
    "        disc_pred = self.d_layer(intermed_pred)\n",
    "        q_pred = self.q_layer1(intermed_pred)\n",
    "        q_pred = self.q_layer2(q_pred)\n",
    "        return disc_pred.view(len(disc_pred), -1), q_pred.view(len(q_pred), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a93df1b234fe387a9647aa20fe4649a2d92c143806d78e3c880e57c28f53f41"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
